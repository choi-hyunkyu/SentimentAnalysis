{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "SentimentAnalysis_movie.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1dmHFwTj7F5",
        "outputId": "5440c3dd-c699-4083-ae09-2484ebcde238"
      },
      "source": [
        "!pip install konlpy\n",
        "from konlpy.tag import Komoran, Okt\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.2.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UL92rXDj7F6",
        "outputId": "49aa9794-97e7-436d-d418-e7534c5cd5ef"
      },
      "source": [
        "%matplotlib inline\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(515)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9e1ee18888>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Z_pjQNGlYf",
        "outputId": "bc22cd9a-a3cf-406f-f681-56c36c27b342"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIdEVAl4j7F7",
        "outputId": "ebdeb8cc-9801-40e9-a7b7-193e6a7ed9cd"
      },
      "source": [
        "!git clone https://github.com/choi-hyunkyu/data.git\n",
        "#tokenizer = Komoran()\n",
        "tokenizer = Okt()\n",
        "original_data_df = pd.read_csv('./data/data/movie_rating_data.csv')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ziKKidRvj7F7",
        "outputId": "4fad3155-b2d5-41e0-bfa2-f21a4b468465"
      },
      "source": [
        "original_data_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-N20LoWj7F8",
        "outputId": "84ab0a83-fead-404c-abb5-f953f3fbbc01"
      },
      "source": [
        "original_data_df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200000 entries, 0 to 199999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count   Dtype \n",
            "---  ------    --------------   ----- \n",
            " 0   id        200000 non-null  int64 \n",
            " 1   document  199992 non-null  object\n",
            " 2   label     200000 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 4.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDW1XjzGj7F9"
      },
      "source": [
        "input_data = original_data_df.drop(['id'], axis = 1).astype('str')[:20000]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hBeyr6QCj7F9",
        "outputId": "407a6338-8c99-42a6-eb30-8c619c67afc8"
      },
      "source": [
        "input_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document label\n",
              "0                                아 더빙.. 진짜 짜증나네요 목소리     0\n",
              "1                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나     1\n",
              "2                                  너무재밓었다그래서보는것을추천한다     0\n",
              "3                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정     0\n",
              "4  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zDqOxaBXNjo",
        "outputId": "667df328-925c-460c-f112-d5cdce84bd8b"
      },
      "source": [
        "input_data.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aG9COpUj7F-"
      },
      "source": [
        "# preprocessing\n",
        "def visualizing_length(text):\n",
        "    max_len = max(len(l) for l in text)\n",
        "    min_len = min(len(l) for l in text)\n",
        "    avg_len = (sum(map(len, text))/len(text))\n",
        "    print('최대 길이 : %d' % max_len)\n",
        "    print('최소 길이 : %d' % min_len)\n",
        "    print('평균 길이 : %f' % avg_len)\n",
        "    plt.hist([len(s) for s in text], bins=50)\n",
        "    plt.xlabel('length of sample')\n",
        "    plt.ylabel('number of sample')\n",
        "    plt.show()\n",
        "    return max_len, min_len, avg_len\n",
        "\n",
        "def vocab(text_df):\n",
        "    out_df = length_normalizing(text_df)\n",
        "    out_df = normalizeString_df(out_df)\n",
        "    out_df = strip_df(out_df)\n",
        "    out_df = empty2nan(out_df)\n",
        "    out_df = deleteNan(out_df)\n",
        "    out_df = shuffle_df(out_df)\n",
        "    label_list = out_df[out_df.keys()[1]].tolist()\n",
        "    text_list = out_df[out_df.keys()[0]].tolist()\n",
        "    token = tokenizing(text_list)\n",
        "    output = uniquewords(token)\n",
        "    words = word2index(output)\n",
        "    words['<PAD>'] = 0\n",
        "    words['<OOV>'] = 1\n",
        "    return token, words, len(words), label_list\n",
        "\n",
        "def word2index(unique_word_list):\n",
        "    return {value: index+2 for index, value in enumerate(unique_word_list)}\n",
        "\n",
        "def uniquewords(word_list):\n",
        "    return list(set([i for value in word_list for i in value]))\n",
        "\n",
        "def tokenizing(text_list):\n",
        "    return [tokenizer.morphs(sentence) for sentence in text_list]\n",
        "\n",
        "def shuffle_df(text_df):\n",
        "    return text_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "def deleteNan(text_df):\n",
        "    text_df = text_df.dropna(how = 'any').reset_index(drop=True)\n",
        "    return text_df\n",
        "\n",
        "def empty2nan(text_df):\n",
        "    text_df[text_df.keys()[0]] = text_df[text_df.keys()[0]].replace('', np.nan)\n",
        "    return text_df\n",
        "\n",
        "def strip_df(text_df):\n",
        "    sub_list = [text.strip() for text in text_df[text_df.keys()[0]]]\n",
        "    text_df[text_df.keys()[0]] = sub_list\n",
        "    return text_df.reset_index(drop=True)\n",
        "\n",
        "def normalizeString_df(text_df):\n",
        "    text_list = [normalizeString(sentence) for sentence in text_df[text_df.keys()[0]]]\n",
        "    input_df = pd.DataFrame({text_df.keys()[0]: text_list})\n",
        "    label_df = text_df.drop(text_df.keys()[0], axis = 1)\n",
        "    fixed_df = pd.concat([input_df, label_df], axis = 1)\n",
        "    return fixed_df\n",
        "\n",
        "def normalizeString(s):\n",
        "    hangul = re.compile('[^ ㄱ-ㅣ가-힣 ^☆.!?]+')\n",
        "    result = hangul.sub('', s)\n",
        "    result = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', result)\n",
        "    return result\n",
        "\n",
        "def length_normalizing(text_df):\n",
        "    for i, v in enumerate(text_df[text_df.keys()[0]]):\n",
        "        if len(text_df[text_df.keys()[0]][i]) > 25 or len(text_df[text_df.keys()[0]][i]) < 10:\n",
        "            text_df.drop(index=[i], inplace=True)\n",
        "    return text_df.reset_index(drop=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwWfCmNdj7F-"
      },
      "source": [
        "# utils\n",
        "def train(model, criterion, optimizer, nb_epochs, \n",
        "          input_size, train_dataloader, validation_dataloader):\n",
        "    \n",
        "    # Train loop\n",
        "    trn_loss_list = []\n",
        "    val_loss_list = []\n",
        "    for epoch in range(nb_epochs):\n",
        "\n",
        "        # Train\n",
        "        trn_loss = 0.0\n",
        "        for trn_batch, train_samples in enumerate(train_dataloader):\n",
        "\n",
        "            # train data setting\n",
        "            x_train, y_train = train_samples\n",
        "            x_train = x_train.unsqueeze(0).to(device)\n",
        "            y_train = y_train.view(-1).long().to(device)\n",
        "\n",
        "            # train\n",
        "            model.train()\n",
        "            hypothesis = model(x_train).view(-1, hidden_size)\n",
        "            optimizer.zero_grad()\n",
        "            train_loss = criterion(hypothesis, y_train)\n",
        "            train_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "            # train loss\n",
        "            trn_loss += train_loss.item() / len(train_dataloader)\n",
        "        trn_loss_list.append(trn_loss)\n",
        "\n",
        "        # Evaluation\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0.0\n",
        "            for val_batch, validation_samples in enumerate(validation_dataloader):\n",
        "\n",
        "                # validatoin data setting\n",
        "                x_validation, y_validation = validation_samples\n",
        "                x_validation = x_validation.unsqueeze(0).to(device)\n",
        "                y_validation = y_validation.view(-1).long().to(device)\n",
        "\n",
        "                # evaluation\n",
        "                model.eval()\n",
        "                prediction = model(x_validation).view(-1, hidden_size)\n",
        "                validation_loss = criterion(prediction, y_validation)\n",
        "\n",
        "                # validation loss\n",
        "                val_loss += validation_loss.item() / len(validation_dataloader)\n",
        "            val_loss_list.append(val_loss)\n",
        "\n",
        "        print(\"Epoch: {:3d} | Train Loss: {:.6f} | Val Loss: {:.6f}\".format(epoch + 1, trn_loss, val_loss))\n",
        "    #torch.save(model, './data/temperature_model.pt')\n",
        "    return trn_loss_list, val_loss_list\n",
        "\n",
        "def checkdata(dataloader):\n",
        "    for index, value in enumerate(dataloader):\n",
        "        while index < 6:\n",
        "            x, y = value\n",
        "            print(\"{} Batch\".format(index))\n",
        "            print(\"Input: {}\".format(x.shape))\n",
        "            print(\"Target: {}\".format(y.shape))\n",
        "            break\n",
        "\n",
        "def checkfunction(dataloader, epoch):\n",
        "    for batch, value in enumerate(dataloader):\n",
        "      x_, y_ = value\n",
        "      print(batch)\n",
        "      x_ = x_.unsqueeze(0).to(device)\n",
        "      print(x_.size())\n",
        "      hypothesis = model(x_).view(-1, hidden_size)\n",
        "      print(hypothesis.size())\n",
        "      y_ = y_.view(-1).long().to(device)\n",
        "      print(y_.size())\n",
        "      loss = criterion(hypothesis, y_)\n",
        "      print(loss)\n",
        "      print()\n",
        "      if batch == epoch:\n",
        "        break\n",
        "\n",
        "def SplitData(encoded_ip, label):\n",
        "    total_size = len(encoded_ip)\n",
        "\n",
        "    train_input_data = encoded_ip[0:int(total_size * 0.7)]\n",
        "    train_target_data = label[0:int(total_size * 0.7)]\n",
        "\n",
        "    validation_input_data = encoded_ip[int(total_size * 0.7):]\n",
        "    validation_target_data = label[int(total_size * 0.7):]\n",
        "    \n",
        "    return (train_input_data, \n",
        "            train_target_data, \n",
        "            validation_input_data, \n",
        "            validation_target_data)\n",
        "\n",
        "def MakeDataset(input_data, target_data):\n",
        "    dataset_size = len(input_data)\n",
        "    input_ts = torch.FloatTensor(np.array(input_data))\n",
        "    target_ts = torch.FloatTensor(np.array(target_data).astype('float64')).view(-1, 1)\n",
        "    dataset = data.TensorDataset(input_ts, target_ts)\n",
        "    return dataset, dataset_size\n",
        "\n",
        "def MakeDataLoader(dataset, batch_size):\n",
        "    return data.DataLoader(dataset, batch_size = batch_size, shuffle = True, drop_last = True)\n",
        "\n",
        "def integerEncoding(tokenized_data, vocab):\n",
        "    encoded = []\n",
        "    for line in tokenized_data:\n",
        "        temp = []\n",
        "        for w in line:\n",
        "            try:\n",
        "                temp.append(vocab[w])\n",
        "            except KeyError:\n",
        "                temp.append(vocab['<OOV>'])\n",
        "        encoded.append(temp)\n",
        "    return encoded\n",
        "    \n",
        "def padding(encoded, vocab, max_length):\n",
        "    for line in encoded:\n",
        "        if len(line) < max_length:\n",
        "            line += [vocab['<PAD>']] * (max_length - len(line))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr93JtZd9K-M"
      },
      "source": [
        "# model\r\n",
        "class BILSTM(nn.Module):\r\n",
        "    def __init__(self, input_size, batch_size, hidden_size, num_layers, vocab_size, embedding_dim, dropout_p = 0.2):\r\n",
        "        super(BILSTM, self).__init__()\r\n",
        "        \r\n",
        "        self.input_size = input_size\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.num_layers = num_layers\r\n",
        "        self.vocab_size = vocab_size\r\n",
        "        self.embedding_dim = embedding_dim\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\r\n",
        "        self.lstm = nn.LSTM(\r\n",
        "            input_size = self.input_size,\r\n",
        "            hidden_size = self.hidden_size,\r\n",
        "            num_layers = self.num_layers,\r\n",
        "            dropout = 0.3,\r\n",
        "            #batch_first = True,\r\n",
        "            bidirectional = True)\r\n",
        "        self.fc = nn.Linear(\r\n",
        "            in_features = self.hidden_size * 2, \r\n",
        "            out_features = self.hidden_size, \r\n",
        "            bias = True)\r\n",
        "        nn.init.xavier_uniform_(self.fc.weight)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        # init hidden and cell state\r\n",
        "        h_0 = torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_size).to(device)\r\n",
        "        c_0 = torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_size).to(device)\r\n",
        "        # forward pass\r\n",
        "        out, _ = self.lstm(x, (h_0, c_0))\r\n",
        "        out = self.fc(out)        \r\n",
        "        return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "aYi_pysorCy9",
        "outputId": "076a7b17-2b56-4e90-9510-9a650bfd766e"
      },
      "source": [
        "_, _, average_length = visualizing_length(input_data['document'].astype('str').tolist())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최대 길이 : 144\n",
            "최소 길이 : 1\n",
            "평균 길이 : 35.368750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2Uf-mu4pqfM"
      },
      "source": [
        "max_length_ip = int(round(average_length))\r\n",
        "batch_size = 32\r\n",
        "input_size = max_length_ip\r\n",
        "num_layers = 2\r\n",
        "embedding_dim = 64\r\n",
        "hidden_size = 128\r\n",
        "learning_rate = 1e-5\r\n",
        "max_norm = 5 # gradient clipping\r\n",
        "nb_epochs = 100"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "354nSvaMj7F_"
      },
      "source": [
        "tokenized_ip, words_ip, num_vocab, label = vocab(input_data)\n",
        "encoded_ip = integerEncoding(tokenized_ip, words_ip)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "h0NZDD5mwYNk",
        "outputId": "537d6339-dc92-4b60-87ea-416b7c3e4176"
      },
      "source": [
        "_, _, _ = visualizing_length([' '.join(lst) for lst in tokenized_ip])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최대 길이 : 38\n",
            "최소 길이 : 1\n",
            "평균 길이 : 17.883212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY3VNEBgwmi1"
      },
      "source": [
        "padding(encoded_ip, words_ip, max_length_ip)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv4YEYCIj7F_",
        "outputId": "cf406a03-03e3-4f05-a332-e6f5a8108a2a"
      },
      "source": [
        "print(\"vocab length:\", num_vocab)\n",
        "print(tokenized_ip[:3])\n",
        "print([' '.join(lst) for lst in tokenized_ip][:3])\n",
        "print(label[:3])\n",
        "print(encoded_ip[:3])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab length: 10451\n",
            "[['애절한', '사랑', '은', '인정', '하는데', '지루한', '것', '은', '왜', '일까'], ['손발', '이', '오글거리다', '못', '해', '없어지겠다'], ['전형', '적', '인', '급', '에로', '코미디', '극']]\n",
            "['애절한 사랑 은 인정 하는데 지루한 것 은 왜 일까', '손발 이 오글거리다 못 해 없어지겠다', '전형 적 인 급 에로 코미디 극']\n",
            "['0', '0', '0']\n",
            "[[8107, 6407, 4979, 9814, 486, 3959, 8891, 4979, 6271, 3642, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5901, 9404, 3705, 6082, 3435, 2722, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [6618, 8458, 5211, 3019, 8056, 9743, 4402, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luwiXU4qj7GA"
      },
      "source": [
        "trn_input, trn_target, val_input, val_target = SplitData(encoded_ip, label)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZyKMv6sj7GB"
      },
      "source": [
        "trn_dataset, trn_dataset_size = MakeDataset(trn_input, trn_target)\n",
        "trn_dataloader = MakeDataLoader(trn_dataset, batch_size)\n",
        "\n",
        "val_dataset, val_dataset_size = MakeDataset(val_input, val_target)\n",
        "val_dataloader = MakeDataLoader(val_dataset, batch_size)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivnLP6J0j7GB",
        "outputId": "6dec04bf-a291-4f4e-858d-4ea1528ed9fa"
      },
      "source": [
        "print(checkdata(trn_dataloader))\r\n",
        "print(checkdata(val_dataloader))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "1 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "2 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "3 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "4 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "5 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "None\n",
            "0 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "1 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "2 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "3 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "4 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "5 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekLZQnYMj7GB"
      },
      "source": [
        "model = BILSTM(input_size, batch_size, hidden_size, num_layers, num_vocab, embedding_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLtQ0GKej7GB",
        "outputId": "860a483e-654e-4d70-e9fc-f10e58f41699"
      },
      "source": [
        "print(model)\n",
        "print(criterion)\n",
        "print(optimizer)\n",
        "print(checkfunction(trn_dataloader, epoch = 5))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BILSTM(\n",
            "  (embedding): Embedding(10451, 64)\n",
            "  (lstm): LSTM(35, 128, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  (fc): Linear(in_features=256, out_features=128, bias=True)\n",
            ")\n",
            "CrossEntropyLoss()\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 1e-05\n",
            "    weight_decay: 0\n",
            ")\n",
            "0\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.9090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "1\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.8709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "2\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.9248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "3\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.8809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "4\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.9415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "5\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.8801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op005dhnj7GB",
        "outputId": "dc82ff65-82e4-4807-f49f-ccd314d3998b"
      },
      "source": [
        "trn_loss, val_loss = train(model, criterion, optimizer, nb_epochs, \n",
        "                           input_size, trn_dataloader, val_dataloader)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   1 | Train Loss: 4.833408 | Val Loss: 4.769147\n",
            "Epoch:   2 | Train Loss: 4.709759 | Val Loss: 4.637424\n",
            "Epoch:   3 | Train Loss: 4.573015 | Val Loss: 4.492557\n",
            "Epoch:   4 | Train Loss: 4.425935 | Val Loss: 4.338594\n",
            "Epoch:   5 | Train Loss: 4.263723 | Val Loss: 4.157048\n",
            "Epoch:   6 | Train Loss: 4.081630 | Val Loss: 3.960287\n",
            "Epoch:   7 | Train Loss: 3.878100 | Val Loss: 3.745866\n",
            "Epoch:   8 | Train Loss: 3.657281 | Val Loss: 3.502039\n",
            "Epoch:   9 | Train Loss: 3.415827 | Val Loss: 3.248108\n",
            "Epoch:  10 | Train Loss: 3.151988 | Val Loss: 2.974685\n",
            "Epoch:  11 | Train Loss: 2.883504 | Val Loss: 2.696429\n",
            "Epoch:  12 | Train Loss: 2.595554 | Val Loss: 2.396528\n",
            "Epoch:  13 | Train Loss: 2.312809 | Val Loss: 2.102926\n",
            "Epoch:  14 | Train Loss: 2.025169 | Val Loss: 1.830642\n",
            "Epoch:  15 | Train Loss: 1.776156 | Val Loss: 1.594502\n",
            "Epoch:  16 | Train Loss: 1.549275 | Val Loss: 1.390224\n",
            "Epoch:  17 | Train Loss: 1.355707 | Val Loss: 1.220633\n",
            "Epoch:  18 | Train Loss: 1.197437 | Val Loss: 1.083187\n",
            "Epoch:  19 | Train Loss: 1.071489 | Val Loss: 0.984687\n",
            "Epoch:  20 | Train Loss: 0.977876 | Val Loss: 0.909874\n",
            "Epoch:  21 | Train Loss: 0.906257 | Val Loss: 0.855994\n",
            "Epoch:  22 | Train Loss: 0.858787 | Val Loss: 0.816920\n",
            "Epoch:  23 | Train Loss: 0.819873 | Val Loss: 0.789866\n",
            "Epoch:  24 | Train Loss: 0.789998 | Val Loss: 0.769564\n",
            "Epoch:  25 | Train Loss: 0.770126 | Val Loss: 0.754127\n",
            "Epoch:  26 | Train Loss: 0.753424 | Val Loss: 0.743422\n",
            "Epoch:  27 | Train Loss: 0.743397 | Val Loss: 0.735211\n",
            "Epoch:  28 | Train Loss: 0.734725 | Val Loss: 0.729252\n",
            "Epoch:  29 | Train Loss: 0.727590 | Val Loss: 0.723699\n",
            "Epoch:  30 | Train Loss: 0.720183 | Val Loss: 0.720060\n",
            "Epoch:  31 | Train Loss: 0.715300 | Val Loss: 0.717564\n",
            "Epoch:  32 | Train Loss: 0.713706 | Val Loss: 0.714745\n",
            "Epoch:  33 | Train Loss: 0.708602 | Val Loss: 0.712893\n",
            "Epoch:  34 | Train Loss: 0.705286 | Val Loss: 0.711508\n",
            "Epoch:  35 | Train Loss: 0.704906 | Val Loss: 0.709757\n",
            "Epoch:  36 | Train Loss: 0.702147 | Val Loss: 0.708029\n",
            "Epoch:  37 | Train Loss: 0.701205 | Val Loss: 0.707639\n",
            "Epoch:  38 | Train Loss: 0.697312 | Val Loss: 0.706657\n",
            "Epoch:  39 | Train Loss: 0.696087 | Val Loss: 0.705476\n",
            "Epoch:  40 | Train Loss: 0.694702 | Val Loss: 0.704932\n",
            "Epoch:  41 | Train Loss: 0.693081 | Val Loss: 0.704124\n",
            "Epoch:  42 | Train Loss: 0.692859 | Val Loss: 0.703481\n",
            "Epoch:  43 | Train Loss: 0.690778 | Val Loss: 0.702861\n",
            "Epoch:  44 | Train Loss: 0.690781 | Val Loss: 0.702222\n",
            "Epoch:  45 | Train Loss: 0.689792 | Val Loss: 0.702558\n",
            "Epoch:  46 | Train Loss: 0.688112 | Val Loss: 0.701625\n",
            "Epoch:  47 | Train Loss: 0.688630 | Val Loss: 0.701328\n",
            "Epoch:  48 | Train Loss: 0.686842 | Val Loss: 0.701259\n",
            "Epoch:  49 | Train Loss: 0.685123 | Val Loss: 0.700797\n",
            "Epoch:  50 | Train Loss: 0.685245 | Val Loss: 0.700262\n",
            "Epoch:  51 | Train Loss: 0.685377 | Val Loss: 0.700119\n",
            "Epoch:  52 | Train Loss: 0.683044 | Val Loss: 0.700288\n",
            "Epoch:  53 | Train Loss: 0.682754 | Val Loss: 0.699827\n",
            "Epoch:  54 | Train Loss: 0.682300 | Val Loss: 0.699315\n",
            "Epoch:  55 | Train Loss: 0.680983 | Val Loss: 0.699194\n",
            "Epoch:  56 | Train Loss: 0.681004 | Val Loss: 0.699909\n",
            "Epoch:  57 | Train Loss: 0.680880 | Val Loss: 0.699265\n",
            "Epoch:  58 | Train Loss: 0.680909 | Val Loss: 0.699002\n",
            "Epoch:  59 | Train Loss: 0.680400 | Val Loss: 0.698882\n",
            "Epoch:  60 | Train Loss: 0.679116 | Val Loss: 0.699196\n",
            "Epoch:  61 | Train Loss: 0.678932 | Val Loss: 0.698881\n",
            "Epoch:  62 | Train Loss: 0.678558 | Val Loss: 0.699242\n",
            "Epoch:  63 | Train Loss: 0.677537 | Val Loss: 0.699049\n",
            "Epoch:  64 | Train Loss: 0.677138 | Val Loss: 0.699084\n",
            "Epoch:  65 | Train Loss: 0.675973 | Val Loss: 0.698386\n",
            "Epoch:  66 | Train Loss: 0.675931 | Val Loss: 0.698946\n",
            "Epoch:  67 | Train Loss: 0.675036 | Val Loss: 0.698934\n",
            "Epoch:  68 | Train Loss: 0.675324 | Val Loss: 0.698821\n",
            "Epoch:  69 | Train Loss: 0.674081 | Val Loss: 0.699573\n",
            "Epoch:  70 | Train Loss: 0.673749 | Val Loss: 0.699073\n",
            "Epoch:  71 | Train Loss: 0.672667 | Val Loss: 0.698671\n",
            "Epoch:  72 | Train Loss: 0.673288 | Val Loss: 0.699334\n",
            "Epoch:  73 | Train Loss: 0.674128 | Val Loss: 0.698839\n",
            "Epoch:  74 | Train Loss: 0.673055 | Val Loss: 0.699355\n",
            "Epoch:  75 | Train Loss: 0.672632 | Val Loss: 0.699357\n",
            "Epoch:  76 | Train Loss: 0.672123 | Val Loss: 0.699925\n",
            "Epoch:  77 | Train Loss: 0.670956 | Val Loss: 0.698811\n",
            "Epoch:  78 | Train Loss: 0.670037 | Val Loss: 0.700073\n",
            "Epoch:  79 | Train Loss: 0.669930 | Val Loss: 0.699414\n",
            "Epoch:  80 | Train Loss: 0.668935 | Val Loss: 0.699796\n",
            "Epoch:  81 | Train Loss: 0.669419 | Val Loss: 0.699756\n",
            "Epoch:  82 | Train Loss: 0.669795 | Val Loss: 0.699549\n",
            "Epoch:  83 | Train Loss: 0.669413 | Val Loss: 0.700341\n",
            "Epoch:  84 | Train Loss: 0.669208 | Val Loss: 0.700403\n",
            "Epoch:  85 | Train Loss: 0.668122 | Val Loss: 0.700000\n",
            "Epoch:  86 | Train Loss: 0.668497 | Val Loss: 0.700185\n",
            "Epoch:  87 | Train Loss: 0.667385 | Val Loss: 0.700889\n",
            "Epoch:  88 | Train Loss: 0.668275 | Val Loss: 0.700038\n",
            "Epoch:  89 | Train Loss: 0.666245 | Val Loss: 0.700313\n",
            "Epoch:  90 | Train Loss: 0.665933 | Val Loss: 0.700867\n",
            "Epoch:  91 | Train Loss: 0.665868 | Val Loss: 0.701106\n",
            "Epoch:  92 | Train Loss: 0.665470 | Val Loss: 0.701177\n",
            "Epoch:  93 | Train Loss: 0.664402 | Val Loss: 0.701645\n",
            "Epoch:  94 | Train Loss: 0.664302 | Val Loss: 0.701207\n",
            "Epoch:  95 | Train Loss: 0.663961 | Val Loss: 0.702082\n",
            "Epoch:  96 | Train Loss: 0.664186 | Val Loss: 0.701889\n",
            "Epoch:  97 | Train Loss: 0.665075 | Val Loss: 0.702291\n",
            "Epoch:  98 | Train Loss: 0.664011 | Val Loss: 0.701639\n",
            "Epoch:  99 | Train Loss: 0.664576 | Val Loss: 0.702255\n",
            "Epoch: 100 | Train Loss: 0.664344 | Val Loss: 0.702556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTwqTemKniED"
      },
      "source": [
        "# 과적합 해결할것\r\n",
        "# vocab json 파일로 저장해서 둘 것\r\n",
        "# 자모 단위로 중복되는 문자열 제거"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}