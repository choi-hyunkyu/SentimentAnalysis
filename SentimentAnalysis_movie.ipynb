{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "SentimentAnalysis_movie.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1dmHFwTj7F5",
        "outputId": "bde370c2-dcb9-4f14-ff46-33015a7b7731"
      },
      "source": [
        "!pip install konlpy\n",
        "from konlpy.tag import Komoran, Okt\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.2.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UL92rXDj7F6",
        "outputId": "9c3de1f8-2bd6-4154-9c6e-5bd4a00093c3"
      },
      "source": [
        "%matplotlib inline\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(515)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4edd514888>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Z_pjQNGlYf",
        "outputId": "9d403a8e-b298-47ff-de54-44580ca8634e"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIdEVAl4j7F7",
        "outputId": "ea365ca5-3c54-4fc6-a44d-acf858767dd2"
      },
      "source": [
        "!git clone https://github.com/choi-hyunkyu/data.git\n",
        "#tokenizer = Komoran()\n",
        "tokenizer = Okt()\n",
        "original_data_df = pd.read_csv('./data/data/movie_rating_data.csv')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ziKKidRvj7F7",
        "outputId": "b0d02f4b-9d1f-4175-cbeb-592b06067699"
      },
      "source": [
        "original_data_df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-N20LoWj7F8",
        "outputId": "15c1e9d7-fb74-474a-d209-8708e0eb8af5"
      },
      "source": [
        "original_data_df.info()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200000 entries, 0 to 199999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count   Dtype \n",
            "---  ------    --------------   ----- \n",
            " 0   id        200000 non-null  int64 \n",
            " 1   document  199992 non-null  object\n",
            " 2   label     200000 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 4.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDW1XjzGj7F9"
      },
      "source": [
        "input_data = original_data_df.drop(['id'], axis = 1).astype('str')[:20000]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hBeyr6QCj7F9",
        "outputId": "fc797ac0-ccff-4e69-9a4d-4ad729d09628"
      },
      "source": [
        "input_data.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document label\n",
              "0                                아 더빙.. 진짜 짜증나네요 목소리     0\n",
              "1                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나     1\n",
              "2                                  너무재밓었다그래서보는것을추천한다     0\n",
              "3                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정     0\n",
              "4  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zDqOxaBXNjo",
        "outputId": "d4ab0fd4-7761-4312-e822-dbf484c24e76"
      },
      "source": [
        "input_data.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aG9COpUj7F-"
      },
      "source": [
        "# preprocessing\n",
        "def visualizing_length(text):\n",
        "    max_len = max(len(l) for l in text)\n",
        "    min_len = min(len(l) for l in text)\n",
        "    avg_len = (sum(map(len, text))/len(text))\n",
        "    print('최대 길이 : %d' % max_len)\n",
        "    print('최소 길이 : %d' % min_len)\n",
        "    print('평균 길이 : %f' % avg_len)\n",
        "    plt.hist([len(s) for s in text], bins=50)\n",
        "    plt.xlabel('length of sample')\n",
        "    plt.ylabel('number of sample')\n",
        "    plt.show()\n",
        "    return max_len, min_len, avg_len\n",
        "\n",
        "def vocab(text_df):\n",
        "    out_df = length_normalizing(text_df)\n",
        "    out_df = normalizeString_df(out_df)\n",
        "    out_df = strip_df(out_df)\n",
        "    out_df = empty2nan(out_df)\n",
        "    out_df = deleteNan(out_df)\n",
        "    out_df = shuffle_df(out_df)\n",
        "    label_list = out_df[out_df.keys()[1]].tolist()\n",
        "    text_list = out_df[out_df.keys()[0]].tolist()\n",
        "    token = tokenizing(text_list)\n",
        "    output = uniquewords(token)\n",
        "    words = word2index(output)\n",
        "    words['<PAD>'] = 0\n",
        "    words['<OOV>'] = 1\n",
        "    return token, words, len(words), label_list\n",
        "\n",
        "def word2index(unique_word_list):\n",
        "    return {value: index+2 for index, value in enumerate(unique_word_list)}\n",
        "\n",
        "def uniquewords(word_list):\n",
        "    return list(set([i for value in word_list for i in value]))\n",
        "\n",
        "def tokenizing(text_list):\n",
        "    return [tokenizer.morphs(sentence, stem=True) for sentence in text_list]\n",
        "\n",
        "def shuffle_df(text_df):\n",
        "    return text_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "def deleteNan(text_df):\n",
        "    text_df = text_df.dropna(how = 'any').reset_index(drop=True)\n",
        "    return text_df\n",
        "\n",
        "def empty2nan(text_df):\n",
        "    text_df[text_df.keys()[0]] = text_df[text_df.keys()[0]].replace('', np.nan)\n",
        "    return text_df\n",
        "\n",
        "def strip_df(text_df):\n",
        "    sub_list = [text.strip() for text in text_df[text_df.keys()[0]]]\n",
        "    text_df[text_df.keys()[0]] = sub_list\n",
        "    return text_df.reset_index(drop=True)\n",
        "\n",
        "def normalizeString_df(text_df):\n",
        "    text_list = [normalizeString(sentence) for sentence in text_df[text_df.keys()[0]]]\n",
        "    input_df = pd.DataFrame({text_df.keys()[0]: text_list})\n",
        "    label_df = text_df.drop(text_df.keys()[0], axis = 1)\n",
        "    fixed_df = pd.concat([input_df, label_df], axis = 1)\n",
        "    return fixed_df\n",
        "\n",
        "def normalizeString(s):\n",
        "    hangul = re.compile('[^ ㄱ-ㅣ가-힣 ^☆.!?]+')\n",
        "    result = hangul.sub('', s)\n",
        "    result = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', result)\n",
        "    return result\n",
        "\n",
        "def length_normalizing(text_df):\n",
        "    for i, v in enumerate(text_df[text_df.keys()[0]]):\n",
        "        if len(text_df[text_df.keys()[0]][i]) > 25 or len(text_df[text_df.keys()[0]][i]) < 10:\n",
        "            text_df.drop(index=[i], inplace=True)\n",
        "    return text_df.reset_index(drop=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwWfCmNdj7F-"
      },
      "source": [
        "# utils\n",
        "def train(model, criterion, optimizer, nb_epochs, \n",
        "          input_size, train_dataloader, validation_dataloader):\n",
        "    \n",
        "    # Train loop\n",
        "    trn_loss_list = []\n",
        "    val_loss_list = []\n",
        "    for epoch in range(nb_epochs):\n",
        "\n",
        "        # Train\n",
        "        trn_loss = 0.0\n",
        "        for trn_batch, train_samples in enumerate(train_dataloader):\n",
        "\n",
        "            # train data setting\n",
        "            x_train, y_train = train_samples\n",
        "            x_train = x_train.unsqueeze(0).to(device)\n",
        "            y_train = y_train.view(-1).long().to(device)\n",
        "\n",
        "            # train\n",
        "            model.train()\n",
        "            hypothesis = model(x_train).view(-1, hidden_size)\n",
        "            optimizer.zero_grad()\n",
        "            train_loss = criterion(hypothesis, y_train)\n",
        "            train_loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "            # train loss\n",
        "            trn_loss += train_loss.item() / len(train_dataloader)\n",
        "        trn_loss_list.append(trn_loss)\n",
        "\n",
        "        # Evaluation\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0.0\n",
        "            for val_batch, validation_samples in enumerate(validation_dataloader):\n",
        "\n",
        "                # validatoin data setting\n",
        "                x_validation, y_validation = validation_samples\n",
        "                x_validation = x_validation.unsqueeze(0).to(device)\n",
        "                y_validation = y_validation.view(-1).long().to(device)\n",
        "\n",
        "                # evaluation\n",
        "                model.eval()\n",
        "                prediction = model(x_validation).view(-1, hidden_size)\n",
        "                validation_loss = criterion(prediction, y_validation)\n",
        "\n",
        "                # validation loss\n",
        "                val_loss += validation_loss.item() / len(validation_dataloader)\n",
        "            val_loss_list.append(val_loss)\n",
        "\n",
        "        print(\"Epoch: {:3d} | Train Loss: {:.6f} | Val Loss: {:.6f}\".format(epoch + 1, trn_loss, val_loss))\n",
        "    #torch.save(model, './data/temperature_model.pt')\n",
        "    return trn_loss_list, val_loss_list\n",
        "\n",
        "def checkdata(dataloader):\n",
        "    for index, value in enumerate(dataloader):\n",
        "        while index < 6:\n",
        "            x, y = value\n",
        "            print(\"{} Batch\".format(index))\n",
        "            print(\"Input: {}\".format(x.shape))\n",
        "            print(\"Target: {}\".format(y.shape))\n",
        "            break\n",
        "\n",
        "def checkfunction(dataloader, epoch):\n",
        "    for batch, value in enumerate(dataloader):\n",
        "      x_, y_ = value\n",
        "      print(batch)\n",
        "      x_ = x_.unsqueeze(0).to(device)\n",
        "      print(x_.size())\n",
        "      hypothesis = model(x_).view(-1, hidden_size)\n",
        "      print(hypothesis.size())\n",
        "      y_ = y_.view(-1).long().to(device)\n",
        "      print(y_.size())\n",
        "      loss = criterion(hypothesis, y_)\n",
        "      print(loss)\n",
        "      print()\n",
        "      if batch == epoch:\n",
        "        break\n",
        "\n",
        "def SplitData(encoded_ip, label):\n",
        "    total_size = len(encoded_ip)\n",
        "\n",
        "    train_input_data = encoded_ip[0:int(total_size * 0.7)]\n",
        "    train_target_data = label[0:int(total_size * 0.7)]\n",
        "\n",
        "    validation_input_data = encoded_ip[int(total_size * 0.7):]\n",
        "    validation_target_data = label[int(total_size * 0.7):]\n",
        "    \n",
        "    return (train_input_data, \n",
        "            train_target_data, \n",
        "            validation_input_data, \n",
        "            validation_target_data)\n",
        "\n",
        "def MakeDataset(input_data, target_data):\n",
        "    dataset_size = len(input_data)\n",
        "    input_ts = torch.FloatTensor(np.array(input_data))\n",
        "    target_ts = torch.FloatTensor(np.array(target_data).astype('float64')).view(-1, 1)\n",
        "    dataset = data.TensorDataset(input_ts, target_ts)\n",
        "    return dataset, dataset_size\n",
        "\n",
        "def MakeDataLoader(dataset, batch_size):\n",
        "    return data.DataLoader(dataset, batch_size = batch_size, shuffle = True, drop_last = True)\n",
        "\n",
        "def integerEncoding(tokenized_data, vocab):\n",
        "    encoded = []\n",
        "    for line in tokenized_data:\n",
        "        temp = []\n",
        "        for w in line:\n",
        "            try:\n",
        "                temp.append(vocab[w])\n",
        "            except KeyError:\n",
        "                temp.append(vocab['<OOV>'])\n",
        "        encoded.append(temp)\n",
        "    return encoded\n",
        "    \n",
        "def padding(encoded, vocab, max_length):\n",
        "    for line in encoded:\n",
        "        if len(line) < max_length:\n",
        "            line += [vocab['<PAD>']] * (max_length - len(line))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr93JtZd9K-M"
      },
      "source": [
        "# model\r\n",
        "class BILSTM(nn.Module):\r\n",
        "    def __init__(self, input_size, batch_size, hidden_size, num_layers, vocab_size, embedding_dim, dropout_p = 0.2):\r\n",
        "        super(BILSTM, self).__init__()\r\n",
        "        \r\n",
        "        self.input_size = input_size\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.num_layers = num_layers\r\n",
        "        self.vocab_size = vocab_size\r\n",
        "        self.embedding_dim = embedding_dim\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\r\n",
        "        self.lstm = nn.LSTM(\r\n",
        "            input_size = self.input_size,\r\n",
        "            hidden_size = self.hidden_size,\r\n",
        "            num_layers = self.num_layers,\r\n",
        "            dropout = 0.3,\r\n",
        "            #batch_first = True,\r\n",
        "            bidirectional = True)\r\n",
        "        self.fc = nn.Linear(\r\n",
        "            in_features = self.hidden_size * 2, \r\n",
        "            out_features = self.hidden_size, \r\n",
        "            bias = True)\r\n",
        "        nn.init.xavier_uniform_(self.fc.weight)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        # init hidden and cell state\r\n",
        "        h_0 = torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_size).to(device)\r\n",
        "        c_0 = torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_size).to(device)\r\n",
        "        # forward pass\r\n",
        "        out, _ = self.lstm(x, (h_0, c_0))\r\n",
        "        out = self.fc(out)        \r\n",
        "        return out"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "aYi_pysorCy9",
        "outputId": "0051e30d-1c65-4497-de4d-ce62f5141178"
      },
      "source": [
        "_, _, average_length = visualizing_length(input_data['document'].astype('str').tolist())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최대 길이 : 144\n",
            "최소 길이 : 1\n",
            "평균 길이 : 35.368750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2Uf-mu4pqfM"
      },
      "source": [
        "max_length_ip = int(round(average_length))\r\n",
        "batch_size = 32\r\n",
        "input_size = max_length_ip\r\n",
        "num_layers = 2\r\n",
        "embedding_dim = 64\r\n",
        "hidden_size = 128\r\n",
        "learning_rate = 1e-5\r\n",
        "max_norm = 1 # gradient clipping\r\n",
        "nb_epochs = 100"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "354nSvaMj7F_"
      },
      "source": [
        "tokenized_ip, words_ip, num_vocab, label = vocab(input_data)\n",
        "encoded_ip = integerEncoding(tokenized_ip, words_ip)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "h0NZDD5mwYNk",
        "outputId": "18f48f4a-8701-4aa0-f231-d16cbc988b86"
      },
      "source": [
        "_, _, _ = visualizing_length([' '.join(lst) for lst in tokenized_ip])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최대 길이 : 38\n",
            "최소 길이 : 1\n",
            "평균 길이 : 17.605709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY3VNEBgwmi1"
      },
      "source": [
        "padding(encoded_ip, words_ip, max_length_ip)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv4YEYCIj7F_",
        "outputId": "fb829b12-0967-4d88-cc1c-592f892534c6"
      },
      "source": [
        "print(\"vocab length:\", num_vocab)\n",
        "print(tokenized_ip[:3])\n",
        "print([' '.join(lst) for lst in tokenized_ip][:3])\n",
        "print(label[:3])\n",
        "print(encoded_ip[:3])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab length: 6899\n",
            "[['구태의연하다', '끝', '을', '보다'], ['이', '영화', '왜', '출시', '안되다', 'ㅜㅠ'], ['정말', '소름끼치다', '다시', '방영', '해주다', '좋다']]\n",
            "['구태의연하다 끝 을 보다', '이 영화 왜 출시 안되다 ㅜㅠ', '정말 소름끼치다 다시 방영 해주다 좋다']\n",
            "['0', '1', '1']\n",
            "[[6719, 4901, 1887, 4491, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [57, 818, 4637, 4376, 190, 609, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [6074, 38, 5556, 1726, 5851, 4475, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luwiXU4qj7GA"
      },
      "source": [
        "trn_input, trn_target, val_input, val_target = SplitData(encoded_ip, label)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZyKMv6sj7GB"
      },
      "source": [
        "trn_dataset, trn_dataset_size = MakeDataset(trn_input, trn_target)\n",
        "trn_dataloader = MakeDataLoader(trn_dataset, batch_size)\n",
        "\n",
        "val_dataset, val_dataset_size = MakeDataset(val_input, val_target)\n",
        "val_dataloader = MakeDataLoader(val_dataset, batch_size)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivnLP6J0j7GB",
        "outputId": "34f43c01-eb58-4a9f-ab65-35249c3d7aff"
      },
      "source": [
        "print(checkdata(trn_dataloader))\r\n",
        "print(checkdata(val_dataloader))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "1 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "2 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "3 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "4 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "5 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "None\n",
            "0 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "1 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "2 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "3 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "4 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "5 Batch\n",
            "Input: torch.Size([32, 35])\n",
            "Target: torch.Size([32, 1])\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekLZQnYMj7GB"
      },
      "source": [
        "model = BILSTM(input_size, batch_size, hidden_size, num_layers, num_vocab, embedding_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLtQ0GKej7GB",
        "outputId": "f8fc483f-fc79-4142-f8c8-214c31e1c3a4"
      },
      "source": [
        "print(model)\n",
        "print(criterion)\n",
        "print(optimizer)\n",
        "print(checkfunction(trn_dataloader, epoch = 5))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BILSTM(\n",
            "  (embedding): Embedding(6899, 64)\n",
            "  (lstm): LSTM(35, 128, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  (fc): Linear(in_features=256, out_features=128, bias=True)\n",
            ")\n",
            "CrossEntropyLoss()\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 1e-05\n",
            "    weight_decay: 0\n",
            ")\n",
            "0\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.8340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "1\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.8493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "2\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.8829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "3\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.8332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "4\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.8480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "5\n",
            "torch.Size([1, 32, 35])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n",
            "tensor(4.8560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op005dhnj7GB",
        "outputId": "ce9f394d-48d0-4498-b672-23b61b9d726b"
      },
      "source": [
        "trn_loss, val_loss = train(model, criterion, optimizer, nb_epochs, \n",
        "                           input_size, trn_dataloader, val_dataloader)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   1 | Train Loss: 4.780750 | Val Loss: 4.703874\n",
            "Epoch:   2 | Train Loss: 4.623768 | Val Loss: 4.533571\n",
            "Epoch:   3 | Train Loss: 4.451238 | Val Loss: 4.339679\n",
            "Epoch:   4 | Train Loss: 4.256584 | Val Loss: 4.133374\n",
            "Epoch:   5 | Train Loss: 4.042545 | Val Loss: 3.895052\n",
            "Epoch:   6 | Train Loss: 3.802809 | Val Loss: 3.638016\n",
            "Epoch:   7 | Train Loss: 3.537462 | Val Loss: 3.343990\n",
            "Epoch:   8 | Train Loss: 3.245475 | Val Loss: 3.034324\n",
            "Epoch:   9 | Train Loss: 2.933924 | Val Loss: 2.705009\n",
            "Epoch:  10 | Train Loss: 2.611085 | Val Loss: 2.363775\n",
            "Epoch:  11 | Train Loss: 2.276235 | Val Loss: 2.036343\n",
            "Epoch:  12 | Train Loss: 1.954357 | Val Loss: 1.727510\n",
            "Epoch:  13 | Train Loss: 1.657402 | Val Loss: 1.450496\n",
            "Epoch:  14 | Train Loss: 1.397068 | Val Loss: 1.234226\n",
            "Epoch:  15 | Train Loss: 1.195589 | Val Loss: 1.066233\n",
            "Epoch:  16 | Train Loss: 1.040915 | Val Loss: 0.949501\n",
            "Epoch:  17 | Train Loss: 0.938320 | Val Loss: 0.868051\n",
            "Epoch:  18 | Train Loss: 0.863638 | Val Loss: 0.816819\n",
            "Epoch:  19 | Train Loss: 0.814604 | Val Loss: 0.781356\n",
            "Epoch:  20 | Train Loss: 0.780428 | Val Loss: 0.757129\n",
            "Epoch:  21 | Train Loss: 0.755651 | Val Loss: 0.741123\n",
            "Epoch:  22 | Train Loss: 0.740380 | Val Loss: 0.730371\n",
            "Epoch:  23 | Train Loss: 0.729876 | Val Loss: 0.723343\n",
            "Epoch:  24 | Train Loss: 0.720783 | Val Loss: 0.717782\n",
            "Epoch:  25 | Train Loss: 0.715927 | Val Loss: 0.713892\n",
            "Epoch:  26 | Train Loss: 0.712681 | Val Loss: 0.710730\n",
            "Epoch:  27 | Train Loss: 0.706765 | Val Loss: 0.708427\n",
            "Epoch:  28 | Train Loss: 0.704915 | Val Loss: 0.706742\n",
            "Epoch:  29 | Train Loss: 0.701673 | Val Loss: 0.705000\n",
            "Epoch:  30 | Train Loss: 0.698679 | Val Loss: 0.703890\n",
            "Epoch:  31 | Train Loss: 0.697457 | Val Loss: 0.702089\n",
            "Epoch:  32 | Train Loss: 0.697020 | Val Loss: 0.701562\n",
            "Epoch:  33 | Train Loss: 0.694656 | Val Loss: 0.701079\n",
            "Epoch:  34 | Train Loss: 0.691805 | Val Loss: 0.700236\n",
            "Epoch:  35 | Train Loss: 0.691841 | Val Loss: 0.699381\n",
            "Epoch:  36 | Train Loss: 0.691166 | Val Loss: 0.698915\n",
            "Epoch:  37 | Train Loss: 0.688156 | Val Loss: 0.698409\n",
            "Epoch:  38 | Train Loss: 0.688541 | Val Loss: 0.698812\n",
            "Epoch:  39 | Train Loss: 0.686703 | Val Loss: 0.697834\n",
            "Epoch:  40 | Train Loss: 0.687433 | Val Loss: 0.697489\n",
            "Epoch:  41 | Train Loss: 0.685263 | Val Loss: 0.697143\n",
            "Epoch:  42 | Train Loss: 0.684600 | Val Loss: 0.697414\n",
            "Epoch:  43 | Train Loss: 0.683535 | Val Loss: 0.696531\n",
            "Epoch:  44 | Train Loss: 0.685236 | Val Loss: 0.697012\n",
            "Epoch:  45 | Train Loss: 0.682185 | Val Loss: 0.697070\n",
            "Epoch:  46 | Train Loss: 0.682314 | Val Loss: 0.696467\n",
            "Epoch:  47 | Train Loss: 0.682168 | Val Loss: 0.696600\n",
            "Epoch:  48 | Train Loss: 0.681918 | Val Loss: 0.696468\n",
            "Epoch:  49 | Train Loss: 0.680765 | Val Loss: 0.696530\n",
            "Epoch:  50 | Train Loss: 0.679360 | Val Loss: 0.696370\n",
            "Epoch:  51 | Train Loss: 0.679141 | Val Loss: 0.696473\n",
            "Epoch:  52 | Train Loss: 0.678999 | Val Loss: 0.696269\n",
            "Epoch:  53 | Train Loss: 0.678369 | Val Loss: 0.696073\n",
            "Epoch:  54 | Train Loss: 0.678554 | Val Loss: 0.695975\n",
            "Epoch:  55 | Train Loss: 0.676350 | Val Loss: 0.696195\n",
            "Epoch:  56 | Train Loss: 0.677806 | Val Loss: 0.695622\n",
            "Epoch:  57 | Train Loss: 0.675503 | Val Loss: 0.695903\n",
            "Epoch:  58 | Train Loss: 0.676272 | Val Loss: 0.696191\n",
            "Epoch:  59 | Train Loss: 0.674364 | Val Loss: 0.696387\n",
            "Epoch:  60 | Train Loss: 0.673745 | Val Loss: 0.696379\n",
            "Epoch:  61 | Train Loss: 0.674018 | Val Loss: 0.696546\n",
            "Epoch:  62 | Train Loss: 0.674148 | Val Loss: 0.696109\n",
            "Epoch:  63 | Train Loss: 0.674086 | Val Loss: 0.696678\n",
            "Epoch:  64 | Train Loss: 0.674229 | Val Loss: 0.695893\n",
            "Epoch:  65 | Train Loss: 0.672926 | Val Loss: 0.696155\n",
            "Epoch:  66 | Train Loss: 0.671606 | Val Loss: 0.696859\n",
            "Epoch:  67 | Train Loss: 0.671427 | Val Loss: 0.696340\n",
            "Epoch:  68 | Train Loss: 0.671100 | Val Loss: 0.696359\n",
            "Epoch:  69 | Train Loss: 0.670749 | Val Loss: 0.696605\n",
            "Epoch:  70 | Train Loss: 0.671151 | Val Loss: 0.696827\n",
            "Epoch:  71 | Train Loss: 0.670827 | Val Loss: 0.697172\n",
            "Epoch:  72 | Train Loss: 0.669523 | Val Loss: 0.696710\n",
            "Epoch:  73 | Train Loss: 0.667396 | Val Loss: 0.696652\n",
            "Epoch:  74 | Train Loss: 0.670274 | Val Loss: 0.696784\n",
            "Epoch:  75 | Train Loss: 0.670108 | Val Loss: 0.696213\n",
            "Epoch:  76 | Train Loss: 0.668065 | Val Loss: 0.696920\n",
            "Epoch:  77 | Train Loss: 0.669135 | Val Loss: 0.696782\n",
            "Epoch:  78 | Train Loss: 0.668002 | Val Loss: 0.696971\n",
            "Epoch:  79 | Train Loss: 0.666979 | Val Loss: 0.696719\n",
            "Epoch:  80 | Train Loss: 0.664975 | Val Loss: 0.696837\n",
            "Epoch:  81 | Train Loss: 0.666172 | Val Loss: 0.697080\n",
            "Epoch:  82 | Train Loss: 0.666359 | Val Loss: 0.697122\n",
            "Epoch:  83 | Train Loss: 0.664425 | Val Loss: 0.696970\n",
            "Epoch:  84 | Train Loss: 0.664648 | Val Loss: 0.697173\n",
            "Epoch:  85 | Train Loss: 0.665226 | Val Loss: 0.697876\n",
            "Epoch:  86 | Train Loss: 0.661046 | Val Loss: 0.698223\n",
            "Epoch:  87 | Train Loss: 0.661829 | Val Loss: 0.698161\n",
            "Epoch:  88 | Train Loss: 0.663462 | Val Loss: 0.697568\n",
            "Epoch:  89 | Train Loss: 0.663983 | Val Loss: 0.698492\n",
            "Epoch:  90 | Train Loss: 0.661676 | Val Loss: 0.698185\n",
            "Epoch:  91 | Train Loss: 0.661963 | Val Loss: 0.698435\n",
            "Epoch:  92 | Train Loss: 0.661627 | Val Loss: 0.697681\n",
            "Epoch:  93 | Train Loss: 0.660648 | Val Loss: 0.698758\n",
            "Epoch:  94 | Train Loss: 0.661609 | Val Loss: 0.698689\n",
            "Epoch:  95 | Train Loss: 0.660670 | Val Loss: 0.698204\n",
            "Epoch:  96 | Train Loss: 0.659362 | Val Loss: 0.698157\n",
            "Epoch:  97 | Train Loss: 0.660227 | Val Loss: 0.699577\n",
            "Epoch:  98 | Train Loss: 0.658831 | Val Loss: 0.699130\n",
            "Epoch:  99 | Train Loss: 0.659854 | Val Loss: 0.699486\n",
            "Epoch: 100 | Train Loss: 0.657214 | Val Loss: 0.699060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTwqTemKniED"
      },
      "source": [
        "# 과적합 해결할것\r\n",
        "# vocab json 파일로 저장해서 둘 것\r\n",
        "# 자모 단위로 중복되는 문자열 제거"
      ],
      "execution_count": 56,
      "outputs": []
    }
  ]
}