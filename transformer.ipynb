{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "transformer",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1dmHFwTj7F5",
        "outputId": "a23afc83-2118-46d4-f6e3-f79cd6601f28"
      },
      "source": [
        "!pip install konlpy\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "\n",
        "from konlpy.tag import Komoran, Okt\n",
        "from tqdm import tqdm, trange\n",
        "import sentencepiece as spm\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.2.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0UL92rXDj7F6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77e01c96-3a1c-4204-c945-c35d25c5ee45"
      },
      "source": [
        "%matplotlib inline\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(515)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f58dd6f0a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Z_pjQNGlYf",
        "outputId": "0f4b9f8a-cacc-42a5-ffd6-b5b6319d7956"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLowTOjvDcl0",
        "outputId": "3ba9fa8f-728a-4c8f-bfc5-8aca76afb383"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aG9COpUj7F-"
      },
      "source": [
        "# preprocessing\n",
        "def load_vocab(file):\n",
        "    vocab = spm.SentencePieceProcessor()\n",
        "    vocab.load(file)\n",
        "    return vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwWfCmNdj7F-"
      },
      "source": [
        "# utils\n",
        "\n",
        "def train(config, model, criterion, optimizer, trn_dataloader, nb_epochs):\n",
        "    trn_losses = []\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(nb_epochs):\n",
        "        trn_loss = 0.0\n",
        "        for batch, values in enumerate(trn_dataloader):\n",
        "            labels, enc_inputs, dec_inputs = values\n",
        "            labels, enc_inputs, dec_inputs = labels.to(device), enc_inputs.to(device), dec_inputs.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            hypothesis = model(enc_inputs, dec_inputs)\n",
        "            logits = hypothesis[0]\n",
        "            train_loss = criterion(logits, labels)\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            trn_loss += train_loss.item()\n",
        "        trn_losses.append(trn_loss)\n",
        "        print(np.mean(trn_losses))\n",
        "    return trn_losses\n",
        "\n",
        "def _train(model, criterion, optimizer, input_size, output_size,\n",
        "          train_dataloader, validation_dataloader,\n",
        "          nb_epochs):\n",
        "    \n",
        "    # Train loop\n",
        "    trn_loss_list = []\n",
        "    val_loss_list = []\n",
        "    for epoch in range(nb_epochs):\n",
        "\n",
        "        # Train\n",
        "        trn_loss = 0.0\n",
        "        for trn_batch, train_samples in enumerate(train_dataloader):\n",
        "\n",
        "            # train data setting\n",
        "            x_train, y_train = train_samples\n",
        "            x_train = x_train.unsqueeze(0).to(device)\n",
        "            y_train = y_train.float().to(device)\n",
        "\n",
        "            # train\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            hypothesis = model(x_train).view(-1, output_size)\n",
        "            train_loss = criterion(hypothesis, y_train)\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "\n",
        "            # train loss\n",
        "            trn_loss += train_loss.item() / len(train_dataloader)\n",
        "        trn_loss_list.append(trn_loss)\n",
        "\n",
        "        # Evaluation\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0.0\n",
        "            for val_batch, validation_samples in enumerate(validation_dataloader):\n",
        "\n",
        "                # validatoin data setting\n",
        "                x_validation, y_validation = validation_samples\n",
        "                x_validation = x_validation.unsqueeze(0).to(device)\n",
        "                y_validation = y_validation.float().to(device)\n",
        "\n",
        "                # evaluation\n",
        "                model.eval()\n",
        "                prediction = model(x_validation).view(-1, output_size)\n",
        "                validation_loss = criterion(prediction, y_validation)\n",
        "\n",
        "                # validation loss\n",
        "                val_loss += validation_loss.item() / len(validation_dataloader)\n",
        "            val_loss_list.append(val_loss)\n",
        "\n",
        "        print(\"Epoch: {:3d} | Train Loss: {:.6f} | Val Loss: {:.6f}\".format(epoch + 1, trn_loss, val_loss))\n",
        "    #torch.save(model, './data/temperature_model.pt')\n",
        "    return trn_loss_list, val_loss_list\n",
        "\n",
        "def checkdata(dataloader):\n",
        "    for batch, values in enumerate(dataloader):\n",
        "        while batch < 6:\n",
        "            label, enc_inputs, dec_inputs = values\n",
        "            print(\"{} Batch\".format(batch))\n",
        "            print(\"Input: {}\".format(enc_inputs.size()))\n",
        "            print(\"Target: {}\".format(dec_inputs.size()))\n",
        "            break\n",
        "    return label, enc_inputs, dec_inputs\n",
        "\n",
        "def checkfunction(criterion, dataloader, output_size, epoch):\n",
        "    model.train()\n",
        "    for batch, values in enumerate(dataloader):\n",
        "        labels, enc_inputs, dec_inputs = values\n",
        "        labels, enc_inputs, dec_inputs = labels.long().to(device), enc_inputs.to(device), dec_inputs.to(device)\n",
        "        hypothesis = model(enc_inputs, dec_inputs)\n",
        "        logits = hypothesis[0]\n",
        "        loss = criterion(logits, labels)\n",
        "        print(\"Batch:\", batch+1)\n",
        "        print(\"enc_inputs size:\", enc_inputs.size())\n",
        "        print(\"dec_inputs size:\", dec_inputs.size())\n",
        "        print(\"logits\", logits)\n",
        "        print(\"logits size:\", logits.size())\n",
        "        print(\"Loss:\", loss)\n",
        "        print()\n",
        "        if batch == epoch:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh20NkAJQbxP"
      },
      "source": [
        "class Config(dict): \r\n",
        "    __getattr__ = dict.__getitem__\r\n",
        "    __setattr__ = dict.__setitem__\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def load(cls, file):\r\n",
        "        with open(file, 'r') as f:\r\n",
        "            config = json.loads(f.read())\r\n",
        "            return Config(config)\r\n",
        "\r\n",
        "class CustomDataSet(data.Dataset):\r\n",
        "    def __init__(self, vocab, infile):\r\n",
        "\r\n",
        "        self.vocab = vocab\r\n",
        "        self.labels = []\r\n",
        "        self.sentences = []\r\n",
        "\r\n",
        "        line_cnt = 0\r\n",
        "        with open(infile, \"r\") as f:\r\n",
        "            for line in f:\r\n",
        "                line_cnt += 1\r\n",
        "\r\n",
        "        with open(infile, \"r\") as f:\r\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\r\n",
        "                data = json.loads(line)\r\n",
        "                self.labels.append(data[\"label\"])\r\n",
        "                self.sentences.append([vocab.piece_to_id(p) for p in data[\"doc\"]])\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        assert len(self.labels) == len(self.sentences)\r\n",
        "        return len(self.labels)\r\n",
        "    \r\n",
        "    def __getitem__(self, item):\r\n",
        "        return (torch.tensor(self.labels[item]),\r\n",
        "                torch.tensor(self.sentences[item]),\r\n",
        "                torch.tensor([self.vocab.piece_to_id(\"[BOS]\")]))\r\n",
        "        \r\n",
        "def movie_collate_fn(inputs):\r\n",
        "    labels, enc_inputs, dec_inputs = list(zip(*inputs))\r\n",
        "\r\n",
        "    enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True, padding_value=0)\r\n",
        "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\r\n",
        "\r\n",
        "    batch = [\r\n",
        "        torch.stack(labels, dim=0),\r\n",
        "        enc_inputs,\r\n",
        "        dec_inputs,\r\n",
        "    ]\r\n",
        "    return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr93JtZd9K-M"
      },
      "source": [
        "# Model\r\n",
        "class Classification(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        # values\r\n",
        "        self.config = config\r\n",
        "\r\n",
        "        # layers\r\n",
        "        self.transformer = Transformer(self.config)\r\n",
        "        self.projection = nn.Linear(self.config['hidden_size'], self.config['output_size'], bias = False)\r\n",
        "\r\n",
        "    def forward(self, enc_inputs, dec_inputs):\r\n",
        "        dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs = self.transformer(enc_inputs, dec_inputs)\r\n",
        "        dec_outputs, _ = torch.max(dec_outputs, dim=1)\r\n",
        "        logits = self.projection(dec_outputs)\r\n",
        "        return logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs\r\n",
        "\r\n",
        "    def save(self, epoch, loss, score, path):\r\n",
        "        torch.save({\r\n",
        "            \"epoch\": epoch,\r\n",
        "            \"loss\": loss,\r\n",
        "            \"score\": score,\r\n",
        "            \"state_dict\": self.state_dict()\r\n",
        "        }, path)\r\n",
        "    \r\n",
        "    def load(self, path):\r\n",
        "        save = torch.load(path)\r\n",
        "        self.load_state_dict(save[\"state_dict\"])\r\n",
        "        return save[\"epoch\"], save[\"loss\"], save[\"score\"]\r\n",
        "\r\n",
        "class Transformer(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        # values\r\n",
        "        self.config = config\r\n",
        "\r\n",
        "        # layers\r\n",
        "        self.encoder = Encoder(self.config)\r\n",
        "        self.decoder = Decoder(self.config)\r\n",
        "\r\n",
        "    def forward(self, enc_inputs, dec_inputs):\r\n",
        "        enc_outputs, enc_self_attn_probs = self.encoder(enc_inputs)\r\n",
        "        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\r\n",
        "        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7rsH1HFd_ni"
      },
      "source": [
        "# Encoding\r\n",
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.config = config\r\n",
        "\r\n",
        "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.hidden_size)\r\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_enc_seq + 1, self.config.hidden_size))\r\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\r\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        positions = torch.arange(x.size(1), device=x.device, dtype=x.dtype).expand(x.size(0), x.size(1)).contiguous() + 1\r\n",
        "        pos_mask = x.eq(self.config.i_pad)\r\n",
        "        positions.masked_fill_(pos_mask, 0)\r\n",
        "        outputs = self.enc_emb(x) + self.pos_emb(positions)\r\n",
        "        attn_mask = get_attn_pad_mask(x, x, self.config.i_pad)\r\n",
        "\r\n",
        "        attn_probs = []\r\n",
        "        for layer in self.layers:\r\n",
        "            outputs, attn_prob = layer(outputs, attn_mask)\r\n",
        "            attn_probs.append(attn_prob)\r\n",
        "        return outputs, attn_probs\r\n",
        "\r\n",
        "class EncoderLayer(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        # values\r\n",
        "        self.config = config\r\n",
        "\r\n",
        "        # layers\r\n",
        "        self.self_attn = MultiHeadAttention(self.config)\r\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size, eps=self.config.layer_norm_epsilon)\r\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\r\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.hidden_size, eps=self.config.layer_norm_epsilon)\r\n",
        "    \r\n",
        "    def forward(self, x, attn_mask):\r\n",
        "        att_outputs, attn_prob = self.self_attn(x, x, x, attn_mask)\r\n",
        "        att_outputs = self.layer_norm1(x + att_outputs)\r\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\r\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\r\n",
        "        return ffn_outputs, attn_prob\r\n",
        "\r\n",
        "class MultiHeadAttention(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        # values\r\n",
        "        self.config = config\r\n",
        "\r\n",
        "        # layers\r\n",
        "        self.W_Q = nn.Linear(self.config.hidden_size, self.config.n_head * self.config.d_head)\r\n",
        "        self.W_K = nn.Linear(self.config.hidden_size, self.config.n_head * self.config.d_head)\r\n",
        "        self.W_V = nn.Linear(self.config.hidden_size, self.config.n_head * self.config.d_head)\r\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\r\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.hidden_size)\r\n",
        "        self.dropout = nn.Dropout(config.dropout)\r\n",
        "    \r\n",
        "    def forward(self, Q, K, V, attn_mask):\r\n",
        "        batch_size = Q.size(0)\r\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\r\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\r\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\r\n",
        "\r\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\r\n",
        "\r\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\r\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\r\n",
        "        output = self.linear(context)\r\n",
        "        output = self.dropout(output)\r\n",
        "        return output, attn_prob\r\n",
        "\r\n",
        "class PoswiseFeedForwardNet(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        # values\r\n",
        "        self.config = config\r\n",
        "\r\n",
        "        # layers\r\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.hidden_size, out_channels=self.config.d_ff, kernel_size=1)\r\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.hidden_size, kernel_size=1)\r\n",
        "        self.active = F.gelu\r\n",
        "        self.dropout = nn.Dropout(config.dropout)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        output = self.active(self.conv1(x.transpose(1, 2)))\r\n",
        "        output = self.conv2(output).transpose(1, 2)\r\n",
        "        output = self.dropout(output)\r\n",
        "        return output\r\n",
        "\r\n",
        "class ScaledDotProductAttention(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        # values\r\n",
        "        self.config = config\r\n",
        "        self.dropout = nn.Dropout(config.dropout)\r\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\r\n",
        "    \r\n",
        "    def forward(self, Q, K, V, attn_mask):\r\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\r\n",
        "        scores.masked_fill_(attn_mask, -1e9)\r\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\r\n",
        "        attn_prob = self.dropout(attn_prob)\r\n",
        "        context = torch.matmul(attn_prob, V)\r\n",
        "        return context, attn_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "filyb2va6XqV"
      },
      "source": [
        "# Decoding\r\n",
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        # values\r\n",
        "        self.config = config\r\n",
        "\r\n",
        "        # layers\r\n",
        "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.hidden_size)\r\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.hidden_size))\r\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\r\n",
        "\r\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\r\n",
        "    \r\n",
        "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\r\n",
        "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\r\n",
        "        pos_mask = dec_inputs.eq(self.config.i_pad)\r\n",
        "        positions.masked_fill_(pos_mask, 0)\r\n",
        "    \r\n",
        "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\r\n",
        "\r\n",
        "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\r\n",
        "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\r\n",
        "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\r\n",
        "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\r\n",
        "\r\n",
        "        self_attn_probs, dec_enc_attn_probs = [], []\r\n",
        "        for layer in self.layers:\r\n",
        "            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\r\n",
        "            self_attn_probs.append(self_attn_prob)\r\n",
        "            dec_enc_attn_probs.append(dec_enc_attn_prob)\r\n",
        "        return dec_outputs, self_attn_probs, dec_enc_attn_probs\r\n",
        "\r\n",
        "class DecoderLayer(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        # values\r\n",
        "        self.config = config\r\n",
        "\r\n",
        "        # layers\r\n",
        "        self.self_attn = MultiHeadAttention(self.config)\r\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size, eps=self.config.layer_norm_epsilon)\r\n",
        "        self.dec_enc_attn = MultiHeadAttention(self.config)\r\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.hidden_size, eps=self.config.layer_norm_epsilon)\r\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\r\n",
        "        self.layer_norm3 = nn.LayerNorm(self.config.hidden_size, eps=self.config.layer_norm_epsilon)\r\n",
        "    \r\n",
        "    def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\r\n",
        "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\r\n",
        "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\r\n",
        "        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\r\n",
        "        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\r\n",
        "        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\r\n",
        "        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\r\n",
        "        return ffn_outputs, self_attn_prob, dec_enc_attn_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH7JAWPRBrz_"
      },
      "source": [
        "# Encoding/Decoding util functions\r\n",
        "def get_sinusoid_encoding_table(n_seq, hidden_size):\r\n",
        "    def cal_angle(position, i_hidn):\r\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / hidden_size)\r\n",
        "    def get_posi_angle_vec(position):\r\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(hidden_size)]\r\n",
        "\r\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\r\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\r\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\r\n",
        "    return sinusoid_table\r\n",
        "\r\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\r\n",
        "    batch_size, len_q = seq_q.size()\r\n",
        "    batch_size, len_k = seq_k.size()\r\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\r\n",
        "    return pad_attn_mask\r\n",
        "\r\n",
        "def get_attn_decoder_mask(seq):\r\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\r\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\r\n",
        "    return subsequent_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqjI23Y1EPqV"
      },
      "source": [
        "vocab = load_vocab(\"/content/drive/My Drive/data/kowiki.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAWbHNs27AQW"
      },
      "source": [
        "config = Config({\r\n",
        "    \"batch_size\": 128, \r\n",
        "    \"n_enc_vocab\": len(vocab),\r\n",
        "    \"n_dec_vocab\": len(vocab),\r\n",
        "    \"num_sequence\": 64, \r\n",
        "    \"n_enc_seq\": 256,\r\n",
        "    \"n_dec_seq\": 256,\r\n",
        "    \"n_layer\": 6,\r\n",
        "    \"hidden_size\": 256,\r\n",
        "    \"i_pad\": 0,\r\n",
        "    \"d_ff\": 1024,\r\n",
        "    \"n_head\": 4,\r\n",
        "    \"d_head\": 64,\r\n",
        "    \"dropout\": 0.1,\r\n",
        "    \"layer_norm_epsilon\": 1e-12,\r\n",
        "    \"output_size\": 2,\r\n",
        "    \"weight_decay\": 0,\r\n",
        "    \"learning_rate\": 5e-5,\r\n",
        "    \"max_norm\": 5,\r\n",
        "    \"adam_epsilon\": 1e-8,\r\n",
        "    \"warmup_steps\": 0,\r\n",
        "    \"nb_epochs\": 100\r\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50vEbOQXwvS4",
        "outputId": "1f39c971-7f51-43e3-a29f-8f4be4dd32e8"
      },
      "source": [
        "trn_dataset = CustomDataSet(vocab, \"/content/drive/My Drive/data/ratings_train.json\")\r\n",
        "trn_dataloader = data.DataLoader(trn_dataset, batch_size=config['batch_size'], shuffle=True, collate_fn=movie_collate_fn)\r\n",
        "test_dataset = CustomDataSet(vocab, \"/content/drive/My Drive/data/ratings_test.json\")\r\n",
        "test_dataloader = data.DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=movie_collate_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/data/ratings_train.json: 100%|██████████| 149995/149995 [00:05<00:00, 25582.77 lines/s]\n",
            "Loading /content/drive/My Drive/data/ratings_test.json: 100%|██████████| 49997/49997 [00:02<00:00, 24983.40 lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivnLP6J0j7GB",
        "outputId": "bfafd98f-5e5e-409c-fd4a-3c89faaad49a"
      },
      "source": [
        "trn_label, trn_enc_inputs, trn_dec_inputs = checkdata(trn_dataloader)\r\n",
        "test_label, test_enc_inputs, test_dec_inputs = checkdata(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Batch\n",
            "Input: torch.Size([128, 100])\n",
            "Target: torch.Size([128, 1])\n",
            "1 Batch\n",
            "Input: torch.Size([128, 92])\n",
            "Target: torch.Size([128, 1])\n",
            "2 Batch\n",
            "Input: torch.Size([128, 97])\n",
            "Target: torch.Size([128, 1])\n",
            "3 Batch\n",
            "Input: torch.Size([128, 95])\n",
            "Target: torch.Size([128, 1])\n",
            "4 Batch\n",
            "Input: torch.Size([128, 95])\n",
            "Target: torch.Size([128, 1])\n",
            "5 Batch\n",
            "Input: torch.Size([128, 89])\n",
            "Target: torch.Size([128, 1])\n",
            "0 Batch\n",
            "Input: torch.Size([128, 97])\n",
            "Target: torch.Size([128, 1])\n",
            "1 Batch\n",
            "Input: torch.Size([128, 86])\n",
            "Target: torch.Size([128, 1])\n",
            "2 Batch\n",
            "Input: torch.Size([128, 84])\n",
            "Target: torch.Size([128, 1])\n",
            "3 Batch\n",
            "Input: torch.Size([128, 93])\n",
            "Target: torch.Size([128, 1])\n",
            "4 Batch\n",
            "Input: torch.Size([128, 95])\n",
            "Target: torch.Size([128, 1])\n",
            "5 Batch\n",
            "Input: torch.Size([128, 109])\n",
            "Target: torch.Size([128, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPIWBiZnEUXN",
        "outputId": "f3f062a1-5fcd-42e7-e402-600462421881"
      },
      "source": [
        "print(\"Train label:\", trn_label[0])\r\n",
        "print(\"Train encoder input:\", trn_enc_inputs[0])\r\n",
        "print(\"Train decoder input:\", trn_dec_inputs[0])\r\n",
        "print(\"Test label:\", test_label[0])\r\n",
        "print(\"Test encoder input:\", test_enc_inputs[0])\r\n",
        "print(\"Test decoder input:\", test_dec_inputs[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train label: tensor(1)\n",
            "Train encoder input: tensor([ 886, 3616,   85, 3652,  723, 3620,  418,   26, 3668, 3613, 3857, 3664,\n",
            "          10, 1102, 4071, 2723, 3590,  339, 3593, 1920,  139, 3699, 3783,  760,\n",
            "        3817, 2723, 3590,  542,  125, 3062, 4097, 3692,  165, 3592, 2413,  444,\n",
            "        3355, 1421, 3588, 3766,  331, 1453, 3037, 3603,  571, 3719,    9, 3595,\n",
            "        3048, 3588,  247,   96, 3892, 3635, 3587, 4552, 4552, 2378,   26, 3963,\n",
            "        3603, 1744, 3929, 3941, 3882, 3591,  639, 3621, 4163,  571, 3719, 3798,\n",
            "        1234, 3590,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0])\n",
            "Train decoder input: tensor([2])\n",
            "Test label: tensor(0)\n",
            "Test encoder input: tensor([3587, 7191, 3601, 1006, 3603, 3344,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0])\n",
            "Test decoder input: tensor([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7dveVttE1qw"
      },
      "source": [
        "encoder = Encoder(config)\r\n",
        "decoder = Decoder(config)\r\n",
        "\r\n",
        "trn_enc_outputs, trn_enc_attn_probs = encoder(trn_enc_inputs)\r\n",
        "trn_dec_outputs, trn_self_attn_probs, trn_dec_enc_attn_probs = decoder(trn_dec_inputs, trn_enc_inputs, trn_enc_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JLfQYKGE4O1",
        "outputId": "076c3661-c6de-4ec4-dd5e-0e0cb8503da4"
      },
      "source": [
        "print(encoder)\r\n",
        "print(decoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder(\n",
            "  (enc_emb): Embedding(8007, 256)\n",
            "  (pos_emb): Embedding(257, 256)\n",
            "  (layers): ModuleList(\n",
            "    (0): EncoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (1): EncoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (2): EncoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (3): EncoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (4): EncoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (5): EncoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Decoder(\n",
            "  (dec_emb): Embedding(8007, 256)\n",
            "  (pos_emb): Embedding(257, 256)\n",
            "  (layers): ModuleList(\n",
            "    (0): DecoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (dec_enc_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (1): DecoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (dec_enc_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (2): DecoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (dec_enc_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (3): DecoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (dec_enc_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (4): DecoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (dec_enc_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (5): DecoderLayer(\n",
            "      (self_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (dec_enc_attn): MultiHeadAttention(\n",
            "        (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (scaled_dot_attn): ScaledDotProductAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "      (pos_ffn): PoswiseFeedForwardNet(\n",
            "        (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "        (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b07HsKPiG_w2",
        "outputId": "7e1eb9f6-0d72-4e4f-e3d4-cdd0c1fe67e7"
      },
      "source": [
        "print(trn_enc_outputs[0])\r\n",
        "print(trn_enc_attn_probs[0][0][0])\r\n",
        "print(trn_dec_outputs[0])\r\n",
        "print(trn_self_attn_probs[0][0][0])\r\n",
        "print(trn_dec_enc_attn_probs[0][0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3533, -1.2610,  1.6061,  ...,  1.9826, -3.1601,  0.9536],\n",
            "        [-1.6468, -0.0844,  0.2194,  ...,  0.0312,  0.3796,  1.6402],\n",
            "        [-0.5145, -0.8300, -0.4607,  ..., -1.1830,  1.2419,  0.4088],\n",
            "        ...,\n",
            "        [-0.2472,  2.0135, -0.3530,  ...,  2.9525, -1.1697,  0.5054],\n",
            "        [ 0.0717,  1.9396, -0.4761,  ...,  3.1744, -1.0924,  0.6159],\n",
            "        [ 0.0821,  1.8500, -0.4951,  ...,  2.8323, -1.1104,  0.4999]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([[0.0130, 0.0000, 0.0145,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0113, 0.0125, 0.0123,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0081, 0.0174, 0.0183,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0038, 0.0061, 0.0124,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0061, 0.0124,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0038, 0.0061, 0.0124,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([[ 1.7225, -1.7472, -0.2956,  1.2938, -0.1310,  0.3033,  1.2102,  0.6799,\n",
            "          0.2558,  0.7692,  1.1206,  0.8749,  0.4625,  0.7622, -0.1156,  0.0055,\n",
            "          0.1175,  0.1684, -1.7927, -0.0684,  0.1333,  1.3213, -0.5484,  0.5351,\n",
            "          0.0770, -0.8561,  1.3550,  0.6880, -1.3299,  1.3339, -1.0873,  0.1627,\n",
            "         -1.4440,  2.3395,  0.2193, -0.0348, -0.4675,  1.3099,  0.9673,  2.0007,\n",
            "         -0.4274, -1.6630,  0.3979, -0.0168, -0.2896,  1.1472, -0.1231,  0.7067,\n",
            "         -1.6412, -0.1911, -0.6069,  0.3104, -0.4626, -1.5207, -0.7121, -0.2251,\n",
            "         -0.0473, -0.1948, -0.0704,  0.4505,  1.4802, -0.2692,  0.2579, -0.3090,\n",
            "          1.0236, -1.0525,  1.1397,  2.9764, -1.4816, -0.1268,  0.4566, -2.0738,\n",
            "         -0.2728,  0.1440, -0.5781, -0.3566, -0.2252, -0.3588,  0.2559,  0.9187,\n",
            "         -0.1825,  1.0843, -0.3123,  1.9500,  0.2475, -0.1018, -0.1819,  1.8656,\n",
            "          1.7277, -0.7717,  0.5810, -0.5312, -0.8055,  0.8125, -0.0073,  0.9362,\n",
            "          0.3969, -0.1216, -1.1920,  0.9448, -0.6042, -0.5308, -0.8696,  2.9104,\n",
            "          1.1671,  1.0629, -1.7329,  0.7334, -0.8229, -0.1079, -1.8310, -0.1596,\n",
            "          0.8168,  0.9478, -1.1896,  2.3758,  0.4071, -0.3108,  0.2360,  0.3817,\n",
            "         -0.7938,  0.1211, -2.0218, -0.3082, -0.3857, -0.5363, -0.3187, -0.3385,\n",
            "         -0.7865, -0.1010, -0.4527, -0.1101, -2.9227, -0.9582, -0.0376,  1.9101,\n",
            "         -0.0335, -0.7143,  0.3256,  0.5964,  1.0565,  0.6848, -2.2634, -1.3837,\n",
            "          0.6377, -0.1953,  0.4109,  0.4018,  0.0408, -1.2009,  0.3812,  0.8034,\n",
            "         -0.0891,  2.3255,  0.9189,  0.7853,  0.6710, -0.3255, -0.4058,  0.3376,\n",
            "         -1.1495, -1.1042,  0.1594,  0.0537, -0.7512,  0.2703, -0.3825,  1.2195,\n",
            "         -0.8217,  0.4949, -1.7856,  0.6624, -2.8645, -1.3582, -0.9166,  1.6836,\n",
            "          1.6859,  0.8520, -1.1340,  1.6097, -0.6591, -1.1500, -0.3756,  0.8814,\n",
            "          0.1584,  0.6310, -1.0596, -0.7184, -0.6357, -0.2971, -1.0091, -0.3871,\n",
            "         -0.8933,  0.3401, -1.1991, -0.0625,  1.5747,  0.8957, -0.2408, -0.2773,\n",
            "         -0.1816,  0.0362, -1.8685,  0.3403,  0.7227, -0.4026, -0.5675, -0.3658,\n",
            "          0.2284,  1.0546, -0.0041,  0.3474,  0.5471,  1.8661, -0.5553,  1.2393,\n",
            "         -0.5910, -0.8281,  0.9412,  0.3842,  0.6517, -0.5555, -1.0473, -1.1201,\n",
            "         -0.2687, -0.3940, -1.3758,  1.3479,  1.0782, -0.6827, -0.4237,  2.0971,\n",
            "         -2.1964, -1.3278, -1.3586,  0.4456, -0.6637, -0.6502, -0.8676, -1.9300,\n",
            "          0.2716,  0.8346, -0.5643, -0.7134, -0.6855,  1.2399,  0.1234,  1.0662,\n",
            "          1.5122, -0.7808, -0.7978,  0.6872,  0.1043,  0.3774, -1.0486, -0.2515]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([[1.1111]], grad_fn=<SelectBackward>)\n",
            "tensor([[0.0211, 0.0185, 0.0000, 0.0175, 0.0143, 0.0175, 0.0109, 0.0171, 0.0149,\n",
            "         0.0201, 0.0171, 0.0268, 0.0242, 0.0000, 0.0000, 0.0152, 0.0101, 0.0000,\n",
            "         0.0094, 0.0127, 0.0000, 0.0140, 0.0134, 0.0235, 0.0076, 0.0126, 0.0099,\n",
            "         0.0139, 0.0113, 0.0150, 0.0107, 0.0180, 0.0114, 0.0126, 0.0149, 0.0104,\n",
            "         0.0000, 0.0099, 0.0130, 0.0221, 0.0116, 0.0252, 0.0109, 0.0000, 0.0170,\n",
            "         0.0181, 0.0147, 0.0122, 0.0000, 0.0179, 0.0170, 0.0138, 0.0000, 0.0174,\n",
            "         0.0144, 0.0137, 0.0131, 0.0113, 0.0148, 0.0000, 0.0184, 0.0125, 0.0133,\n",
            "         0.0112, 0.0097, 0.0061, 0.0196, 0.0143, 0.0138, 0.0147, 0.0000, 0.0105,\n",
            "         0.0093, 0.0093, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aal-nQHVE27m",
        "outputId": "0992e232-9d2a-437b-b2fd-c4e91e6ecb1c"
      },
      "source": [
        "print(np.shape(trn_enc_outputs))\r\n",
        "print(np.shape(trn_enc_attn_probs))\r\n",
        "print(np.shape(trn_dec_outputs))\r\n",
        "print(np.shape(trn_self_attn_probs))\r\n",
        "print(np.shape(trn_dec_enc_attn_probs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 89, 256])\n",
            "(6,)\n",
            "torch.Size([128, 1, 256])\n",
            "(6,)\n",
            "(6,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekLZQnYMj7GB"
      },
      "source": [
        "model = Classification(config).to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr = config['learning_rate'], eps=config['adam_epsilon'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aLtQ0GKej7GB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac28eee-7f62-4ff9-dd8a-007d2433d55d"
      },
      "source": [
        "print(\"Model:\", model)\n",
        "print(\"Criterion:\", criterion)\n",
        "print(\"Optimizer:\", optimizer)\n",
        "print(checkfunction(criterion = criterion, \n",
        "                    dataloader = trn_dataloader, \n",
        "                    output_size = config['output_size'], epoch = 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: Classification(\n",
            "  (transformer): Transformer(\n",
            "    (encoder): Encoder(\n",
            "      (enc_emb): Embedding(8007, 256)\n",
            "      (pos_emb): Embedding(257, 256)\n",
            "      (layers): ModuleList(\n",
            "        (0): EncoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (1): EncoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (2): EncoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (3): EncoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (4): EncoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (5): EncoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (decoder): Decoder(\n",
            "      (dec_emb): Embedding(8007, 256)\n",
            "      (pos_emb): Embedding(257, 256)\n",
            "      (layers): ModuleList(\n",
            "        (0): DecoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (dec_enc_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (1): DecoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (dec_enc_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (2): DecoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (dec_enc_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (3): DecoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (dec_enc_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (4): DecoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (dec_enc_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (5): DecoderLayer(\n",
            "          (self_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (dec_enc_attn): MultiHeadAttention(\n",
            "            (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (scaled_dot_attn): ScaledDotProductAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "          (pos_ffn): PoswiseFeedForwardNet(\n",
            "            (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
            "            (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (projection): Linear(in_features=256, out_features=2, bias=False)\n",
            ")\n",
            "Criterion: CrossEntropyLoss()\n",
            "Optimizer: AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 5e-05\n",
            "    weight_decay: 0.01\n",
            ")\n",
            "Batch: 1\n",
            "enc_inputs size: torch.Size([128, 89])\n",
            "dec_inputs size: torch.Size([128, 1])\n",
            "logits tensor([[ 3.2237e-01,  7.7782e-01],\n",
            "        [-6.4853e-01,  4.5767e-01],\n",
            "        [ 2.1660e-01,  5.3832e-01],\n",
            "        [-1.1082e-01,  2.7125e-01],\n",
            "        [-1.7295e-01,  9.7984e-01],\n",
            "        [ 3.1304e-01,  4.8283e-01],\n",
            "        [-3.7971e-01,  7.6595e-01],\n",
            "        [-4.2791e-01,  2.5808e-01],\n",
            "        [-8.8504e-01,  8.7101e-01],\n",
            "        [-3.3096e-01,  7.4160e-01],\n",
            "        [ 4.7305e-01,  7.8806e-01],\n",
            "        [-5.6190e-01,  4.4075e-01],\n",
            "        [-2.1637e-01,  1.1292e+00],\n",
            "        [-2.3737e-01,  5.7644e-01],\n",
            "        [-1.7026e-01,  8.5226e-01],\n",
            "        [ 2.1217e-01,  9.7785e-01],\n",
            "        [-4.5779e-01,  6.9289e-01],\n",
            "        [-2.2227e-01,  5.4431e-01],\n",
            "        [-2.6315e-01,  7.4452e-01],\n",
            "        [-3.8619e-01,  6.6292e-04],\n",
            "        [-1.4410e-01,  8.9267e-01],\n",
            "        [-6.5990e-01,  1.0834e+00],\n",
            "        [-4.9590e-01,  7.6889e-01],\n",
            "        [-2.3413e-01,  5.3933e-01],\n",
            "        [ 8.0035e-02,  3.2367e-01],\n",
            "        [-2.1374e-01,  4.0160e-01],\n",
            "        [-2.4046e-01,  3.8045e-01],\n",
            "        [ 1.0555e-01,  3.2536e-01],\n",
            "        [ 2.9028e-01,  3.6301e-01],\n",
            "        [-3.1612e-01,  3.1677e-01],\n",
            "        [-4.9079e-01,  1.0303e+00],\n",
            "        [-3.7328e-01,  6.9286e-01],\n",
            "        [-2.0271e-01,  9.1834e-01],\n",
            "        [ 2.7856e-01,  7.6834e-01],\n",
            "        [-2.0565e-01,  5.7801e-01],\n",
            "        [ 8.8515e-03,  5.2290e-01],\n",
            "        [-2.9417e-01,  1.0063e+00],\n",
            "        [-1.6652e-01, -4.5770e-02],\n",
            "        [-4.0995e-01,  6.4020e-01],\n",
            "        [-2.4825e-01, -1.9008e-01],\n",
            "        [-2.6215e-01,  6.3709e-01],\n",
            "        [-2.4417e-01,  7.2060e-01],\n",
            "        [-6.2486e-02,  5.4618e-01],\n",
            "        [-6.5636e-01,  4.2298e-01],\n",
            "        [-2.6077e-02,  3.5431e-01],\n",
            "        [ 2.0697e-01,  6.6807e-01],\n",
            "        [ 4.6094e-01,  3.6279e-01],\n",
            "        [-4.0576e-01,  7.4757e-01],\n",
            "        [-3.6850e-01,  2.5912e-01],\n",
            "        [-1.4894e-01,  8.4171e-01],\n",
            "        [-2.4302e-01,  9.8283e-01],\n",
            "        [ 2.2317e-02,  3.4098e-01],\n",
            "        [-3.7563e-02,  3.5138e-01],\n",
            "        [-6.7608e-01,  7.2232e-01],\n",
            "        [ 1.6092e-02,  4.7406e-01],\n",
            "        [-3.4142e-02,  1.2184e+00],\n",
            "        [ 4.4676e-02,  7.5727e-01],\n",
            "        [-2.7604e-01,  9.7770e-01],\n",
            "        [-6.7235e-01,  7.8249e-01],\n",
            "        [-3.6626e-02,  7.1035e-01],\n",
            "        [-3.0204e-01,  6.4934e-01],\n",
            "        [-1.6131e-01,  7.1304e-01],\n",
            "        [-4.1639e-01,  5.7762e-01],\n",
            "        [-1.3410e-01,  4.2911e-01],\n",
            "        [-4.8577e-01,  5.9160e-01],\n",
            "        [-1.5146e-01,  7.0065e-01],\n",
            "        [-6.2225e-01,  7.0465e-01],\n",
            "        [-2.3720e-01,  5.8884e-01],\n",
            "        [ 1.3333e-01,  4.6541e-01],\n",
            "        [-4.7976e-01,  4.1135e-01],\n",
            "        [-3.2161e-01,  7.6835e-01],\n",
            "        [ 3.3741e-02,  9.4926e-01],\n",
            "        [ 7.2042e-02,  7.8643e-01],\n",
            "        [-4.2929e-01,  4.6910e-01],\n",
            "        [ 2.3667e-01,  8.4548e-01],\n",
            "        [-1.8292e-01,  1.3817e+00],\n",
            "        [-2.7645e-01,  5.3697e-01],\n",
            "        [-2.4561e-01,  9.5047e-01],\n",
            "        [-1.0732e-01,  3.2582e-01],\n",
            "        [ 2.4751e-01,  2.9136e-01],\n",
            "        [-2.1261e-01,  7.5363e-01],\n",
            "        [-6.8929e-01,  7.9670e-01],\n",
            "        [-2.6958e-01,  3.3663e-01],\n",
            "        [ 3.8620e-01,  7.4749e-01],\n",
            "        [-1.3699e-01,  6.0069e-01],\n",
            "        [-4.1545e-01,  5.6542e-01],\n",
            "        [-1.2897e-01,  3.8098e-01],\n",
            "        [-1.4797e-01,  9.8925e-01],\n",
            "        [-1.0676e-01,  3.8778e-01],\n",
            "        [-1.2850e-01,  3.8885e-01],\n",
            "        [ 1.0330e-01,  5.4341e-01],\n",
            "        [ 2.3852e-02,  5.0666e-01],\n",
            "        [-2.8799e-01,  8.5436e-01],\n",
            "        [-4.6217e-01, -5.8960e-03],\n",
            "        [-4.2406e-01,  8.2541e-01],\n",
            "        [-8.7406e-02,  7.4455e-01],\n",
            "        [-1.3098e-01,  4.3379e-01],\n",
            "        [ 1.1549e-01,  9.5502e-01],\n",
            "        [-3.5031e-01,  2.7756e-01],\n",
            "        [-2.2789e-01,  1.0365e+00],\n",
            "        [ 4.3100e-01,  5.2475e-01],\n",
            "        [-4.5481e-01,  7.5344e-01],\n",
            "        [-1.5152e-01,  1.6306e-01],\n",
            "        [-2.5780e-01,  7.1394e-01],\n",
            "        [-2.1879e-01,  4.1676e-01],\n",
            "        [-4.4292e-01,  7.7672e-01],\n",
            "        [ 4.1142e-02,  3.4978e-01],\n",
            "        [-1.5037e-01,  5.1781e-01],\n",
            "        [-2.9520e-01,  9.4645e-01],\n",
            "        [ 5.4014e-02,  5.4777e-01],\n",
            "        [-7.0874e-02,  4.0992e-01],\n",
            "        [-2.6424e-01,  1.0069e+00],\n",
            "        [ 8.6753e-02,  5.2375e-01],\n",
            "        [-9.3838e-01,  4.1171e-01],\n",
            "        [-5.7121e-02,  7.6392e-01],\n",
            "        [-1.5836e-01,  5.1825e-01],\n",
            "        [-4.2892e-01,  4.4359e-01],\n",
            "        [-4.1455e-01,  3.1992e-01],\n",
            "        [-1.9934e-01,  2.8178e-01],\n",
            "        [ 1.6866e-02, -2.5263e-02],\n",
            "        [-6.8079e-01,  4.7475e-01],\n",
            "        [ 1.7519e-01,  5.5257e-01],\n",
            "        [-3.5443e-01,  5.7554e-01],\n",
            "        [ 7.0073e-02,  5.9240e-01],\n",
            "        [-1.1795e-01,  5.0263e-01],\n",
            "        [ 1.2125e-01,  6.1459e-01],\n",
            "        [-2.0990e-01,  2.5474e-01],\n",
            "        [ 1.7460e-01,  6.7324e-01]], grad_fn=<MmBackward>)\n",
            "logits size: torch.Size([128, 2])\n",
            "Loss: tensor(0.7623, grad_fn=<NllLossBackward>)\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PyEzv1emofm",
        "outputId": "948250ba-a6c2-4f45-ed7f-f3842256d219"
      },
      "source": [
        "nb_epochs = 3\r\n",
        "\r\n",
        "for epoch in range(nb_epochs):\r\n",
        "    losses = []\r\n",
        "    trn_loss = 0.0\r\n",
        "    model.train()\r\n",
        "    for batch, values in enumerate(trn_dataloader):\r\n",
        "        labels, enc_inputs, dec_inputs = values\r\n",
        "        hypothesis = model(enc_inputs, dec_inputs)\r\n",
        "        optimizer.zero_grad()\r\n",
        "        logits = hypothesis[0]\r\n",
        "        loss = criterion(logits, labels)\r\n",
        "        trn_loss += loss.item()\r\n",
        "        losses.append(loss.item())\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        print(\"{} / {}\".format(batch+1, len(trn_dataloader)))\r\n",
        "    print(\"loss\", trn_loss / len(trn_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 / 1172\n",
            "2 / 1172\n",
            "3 / 1172\n",
            "4 / 1172\n",
            "5 / 1172\n",
            "6 / 1172\n",
            "7 / 1172\n",
            "8 / 1172\n",
            "9 / 1172\n",
            "10 / 1172\n",
            "11 / 1172\n",
            "12 / 1172\n",
            "13 / 1172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGD1r0ULFLfT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}